{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123b92d8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-09T11:47:36.059169Z",
     "iopub.status.busy": "2025-06-09T11:47:36.058938Z",
     "iopub.status.idle": "2025-06-09T11:47:37.494406Z",
     "shell.execute_reply": "2025-06-09T11:47:37.493875Z"
    },
    "papermill": {
     "duration": 1.440492,
     "end_time": "2025-06-09T11:47:37.495764",
     "exception": false,
     "start_time": "2025-06-09T11:47:36.055272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9ae57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T11:47:37.502193Z",
     "iopub.status.busy": "2025-06-09T11:47:37.501717Z",
     "iopub.status.idle": "2025-06-09T11:47:37.507602Z",
     "shell.execute_reply": "2025-06-09T11:47:37.507049Z"
    },
    "papermill": {
     "duration": 0.009974,
     "end_time": "2025-06-09T11:47:37.508589",
     "exception": false,
     "start_time": "2025-06-09T11:47:37.498615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Dataset:\\n\\n    def __init__(self, data, *arg, **kwargs):  # 초기화 메서드 (__init__): 입력된 데이터의 전처리 과정을 수행하는 메서드 (학습에 필요한 형태로 변형)\\n        self.data = data\\n\\n    def __get__item(self, index):      # 호출 메서드 (__getitem__) : 학습을 진행할때 index에 해당하는 데이터 샘플을 불러오고 반환하는 메서드 \\n        return tuple(data[index] for data in data.tensors)      # 초기화 메서드에서 변형,개선된 데이터를 가져오며, 데이터 샘플과 정답을 반환한다.\\n\\n    def __len__(self):        # 길이 반환 메서드(__len__) : 학습에 사용된 전체 데이터세트의 개수를 반환한다. \\n        return self.data[0].size(0)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 세트\n",
    "# 학습에 필요한 데이터 샘플을 정제하고 정답을 저장하는 기능을 제공한다.\n",
    "# 클래스 형태로 제공되며,\n",
    "# 초기화 메서드(__init__), 호출 메서드(__getitem__), 길이 반환 메서드(__len__)를 재정의하여 활용한다.\n",
    "\n",
    "# 데이터세트 클래스의 기본형\n",
    "\n",
    "'''\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, data, *arg, **kwargs):  # 초기화 메서드 (__init__): 입력된 데이터의 전처리 과정을 수행하는 메서드 (학습에 필요한 형태로 변형)\n",
    "        self.data = data\n",
    "\n",
    "    def __get__item(self, index):      # 호출 메서드 (__getitem__) : 학습을 진행할때 index에 해당하는 데이터 샘플을 불러오고 반환하는 메서드 \n",
    "        return tuple(data[index] for data in data.tensors)      # 초기화 메서드에서 변형,개선된 데이터를 가져오며, 데이터 샘플과 정답을 반환한다.\n",
    "\n",
    "    def __len__(self):        # 길이 반환 메서드(__len__) : 학습에 사용된 전체 데이터세트의 개수를 반환한다. \n",
    "        return self.data[0].size(0)\n",
    "'''\n",
    "\n",
    "# 모델 학습을 위해 임의의 데이터세트를 구성할 때 파이토치에서 지원하는 데이터 세트 클래스를 상속받아 사용한다.\n",
    "# 새로 정의한 데이터세트 클래스는 현재 시스템에 적합한 구조로 데이터를 전처리해 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3db336c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T11:47:37.513836Z",
     "iopub.status.busy": "2025-06-09T11:47:37.513660Z",
     "iopub.status.idle": "2025-06-09T11:47:37.517196Z",
     "shell.execute_reply": "2025-06-09T11:47:37.516548Z"
    },
    "papermill": {
     "duration": 0.00734,
     "end_time": "2025-06-09T11:47:37.518243",
     "exception": false,
     "start_time": "2025-06-09T11:47:37.510903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "# 데이터 세트에 저장된 데이터를 어떠한 방식으로 불러와 활용할지 정의한다.\n",
    "# 학습을 좀 더 원활하게 진행할수 있도록 배치크기(batch_size), 데이터 순서 변경(shuffle), 데이터 로드 프로세스 수(num_workers)등의 기능을 제공한다.\n",
    "\n",
    "# 배치크기 (batch_size)는 학습에 사용되는 데이터의 개수가 너무 많아서 한번의 에폭에서 모든데이터를 메모리에 올릴 수 없을 때 데이터를 나누는 역할을 한다.\n",
    "# 전체 데이터세트에서 배치 크기 만큼 데이터 샘플을 나누고, 모든 배치를 대상으로 학습을 완료하면 한번의 에폭이 완료된다.\n",
    "#  ex) 1,000개의 데이터 샘플이 데이터 세트의 전체 길이일 떄, 배치크기를 100으로 할당하면 10번의 배치가 완료될때 1번의 에폭이 진행됬다고 볼수있다.\n",
    "\n",
    "# 데이터 순서 변경 (shuffle)은 모델이 데이터 간의 관계가 아닌, 데이터 순서로 학습되는것을 방지하고자 수행하는 기능이다.\n",
    "# 데이터 샘플과 정답의 매핑관계는 변경되지 않으며, 행의 순서를 변경하는 개념이다.\n",
    "\n",
    "# 데이터 로드 프로세스 수 (nun_workers)는 데이터를 불러올 때 사용할 프로세스의 개수를 의미한다.\n",
    "# 학습을 제외한 코드에서는 데이터를 불러오는데 시간이 가장 오래 소요되므로, 이를 최소화하고자 데이터 로드에 필요한 프로세스의 수를 늘릴수있다.\n",
    "\n",
    "# 일반적으로 데이터 세트를 재정의해 가장많이 사용하며, 데이터 로더에서는 주로 배치 크기를 조절해 가면서 현재 학습환경에 맞는 구조로 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510b72bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T11:47:37.523456Z",
     "iopub.status.busy": "2025-06-09T11:47:37.523284Z",
     "iopub.status.idle": "2025-06-09T11:47:46.302509Z",
     "shell.execute_reply": "2025-06-09T11:47:46.301527Z"
    },
    "papermill": {
     "duration": 8.783108,
     "end_time": "2025-06-09T11:47:46.303682",
     "exception": true,
     "start_time": "2025-06-09T11:47:37.520574",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/622914415.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 다중 선형 회귀\n",
    "# 기본 구조 선언\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "    [1,2],[2,3],[3,4],[4,5],[5,6],[6,7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "    [0.1,1.5],[1,2.8],[1.9,4.1],[2.8,5.4],[3.7,6.7],[4.6,8]\n",
    "])\n",
    "\n",
    "# 데이터세트와 데이터로더\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=2, # 한번의 배치마다 두개의 데이터 세트와 정답을 가져옴 \n",
    "                              shuffle=True, # 데이터의 순서를 무작위로 변경\n",
    "                              drop_last=True) # 배치 크기에 맞지 않는 배치를 제거\n",
    "\n",
    "# 모델,오차함수.최적화함수 선언\n",
    "modl = nn.Linear(2, 2, bias=True)  # 다중선형회귀도 선형변환클래스를 사용한다\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(modl.parameters(), lr=0.001)\n",
    "\n",
    "# 데이터로더 적용\n",
    "for epoch in range(2000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c6057",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델/데이터세트 분리\n",
    "\n",
    "# 모듈 클래스\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):   # 초기화 메서드 (__init__):신경망에 사용될 계층을 초기화한다.\n",
    "        super().__init__()  # 계층 정의전에 super함수로 모듈 클래스의 속성을 초기화 \n",
    "        self.conv1 = nn.Conv2d(1,20,5)   #  모델의 매개변수\n",
    "        self.conv2 = nn.Conv2d(20,20,5)  #  모델의 매개변수\n",
    "\n",
    "    def forward(self. x): # 순방향 메서드 (forward):모델이 어떤 구조를 갖게 될지를 정의한다.\n",
    "        x = F.relu(self.conv1(x))    # 데이터(x)를 입력받아 학습을 진행한다\n",
    "        x = F.relu(self.conv2(x))    # 초기화 메서드에서 super함수로 부모클래스를 초기화 했으므로, backward연산은 정의하지 않아도 됨.\n",
    "        return x                     # 파이토치의 Autograd에서 모델의 매개변수를 역으로 전파해 자동으로 기울기 or 변화도를 계산해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c69b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a534",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 비선형회귀\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# 사용자 정의 데이터세트\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# 사용자 정의 모델\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2,1)   # 선형변환함수(nn.Linear)의 입력데이터 차원크기(in_features)는 이차다항식 이므로 2를 입력하고,\n",
    "                                      #                      출력데이터 차원크기(out_features)는 1을 입력한다    \n",
    "    def forward(self, x):                 \n",
    "        x = self.layer(x)             # 순방향 메서드에서 학습과정 정의:\n",
    "        return x                      # 현재 모델 계층이 하나뿐이므로 self.layer변수에 입력 데이터 x를 전달하고 결괏값을 반환한다.\n",
    "\n",
    "# 사용자 정의 데이터세트와 데이터로더\n",
    "train_dataset = CustomDataset(\"../datasets/non_linear.csv\") # train_dataset 변수에 CustomDataset 인스턴스를 생성.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)  # drop_last : 마지막 배치 제거\n",
    "\n",
    "# GPU 연산 적용\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da93de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "with torch no_grad():  # no_grad 클래스 : 기울기 계산을 비활성화 하는 클래스로, 자동미분 기능을 사용하지않도록 설정하여 메모리 사용량을 줄여 추론에 적합한 상태로 변경.\n",
    "    model.eval()      # 모델을 평가모드로 변경\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1 ** 2, 1],\n",
    "            [5 ** 2, 5],\n",
    "            [11 ** 2, 11]\n",
    "        ]\n",
    "    )to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0ed5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(\n",
    "    model,\n",
    "    \"../models/model.pt\"\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"../models/model_state_dict.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6c11e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e50cf6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca6b0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720faca",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21a635",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d652a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.238969,
   "end_time": "2025-06-09T11:47:49.178127",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T11:47:31.939158",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
